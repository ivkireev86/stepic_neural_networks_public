{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run_car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cars.world import SimpleCarWorld\n",
    "from cars.agent import SimpleCarAgent\n",
    "from cars.physics import SimplePhysics\n",
    "from cars.track import generate_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# базовый пример кода\n",
    "```\n",
    "if filename:\n",
    "    agent = SimpleCarAgent.from_file(filename)\n",
    "    w = SimpleCarWorld(1, m, SimplePhysics, SimpleCarAgent, timedelta=0.2)\n",
    "    if evaluate:\n",
    "        print(w.evaluate_agent(agent, steps))\n",
    "    else:\n",
    "        w.set_agents([agent])\n",
    "        w.run(steps)\n",
    "else:\n",
    "    w = SimpleCarWorld(1, m, SimplePhysics, SimpleCarAgent, timedelta=0.2)\n",
    "    w.run(steps)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_map(seed, agent):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    m = generate_map(8, 5, 3, 3)\n",
    "    w = SimpleCarWorld(1, m, SimplePhysics, SimpleCarAgent, timedelta=0.2)\n",
    "    w.set_agents([agent])\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Агент"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "agent = SimpleCarAgent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "agent = SimpleCarAgent.from_file('network_config_agent_0_layers_9_6_1.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_params = [\n",
    "    (0.20, 1000,),\n",
    "    (0.05, 1000,),\n",
    "]\n",
    "\n",
    "map_seeds = [23, 15, 21, 42]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Учим модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on map = 23\n",
      "revard -1.6876659686\n",
      "revard -1.20006878203\n",
      "revard -0.547891006284\n",
      "revard -0.95166024457\n",
      "revard -2.0895342805\n",
      "revard -2.86840708484\n",
      "revard -1.73541390595\n",
      "revard -0.415076768006\n",
      "revard -0.566337963729\n",
      "revard -0.862029498398\n",
      "revard -0.962232237086\n",
      "revard -0.764993703214\n",
      "revard -0.732291607959\n",
      "revard -1.0738954538\n",
      "revard -1.88587089107\n",
      "revard -2.29244218491\n",
      "revard -2.59093935174\n",
      "revard -2.0544639881\n",
      "revard -0.551559431508\n",
      "revard -0.045709427616\n",
      "Saved agent parameters to 'network_config_agent_0_layers_9_6_1.txt'\n",
      "train on map = 15\n",
      "revard -0.110746600897\n",
      "revard -1.11867390173\n",
      "revard -1.08791238443\n",
      "revard -0.54745064058\n",
      "revard -1.35750062921\n",
      "revard -1.36030105315\n",
      "revard -0.717639281373\n",
      "revard -0.719973632371\n",
      "revard -1.35920980407\n",
      "revard -2.90377072342\n",
      "revard -3.99898055588\n",
      "revard -3.14637493338\n",
      "revard -1.62224940876\n",
      "revard -1.00956536552\n",
      "revard -2.04824629072\n",
      "revard -2.71723670442\n",
      "revard -2.58111721422\n",
      "revard -2.79015032281\n",
      "revard -3.168666933\n",
      "revard -3.28708534319\n",
      "Saved agent parameters to 'network_config_agent_0_layers_9_6_1.txt'\n",
      "train on map = 21\n",
      "revard -0.785209423022\n",
      "revard -0.631624732513\n",
      "revard -0.620901397515\n",
      "revard -0.496846259021\n",
      "revard -0.512372182152\n",
      "revard -1.09451256683\n",
      "revard -1.37206645822\n",
      "revard -1.19822061012\n",
      "revard -0.998825790793\n",
      "revard -0.825843733888\n",
      "revard -0.638438386653\n",
      "revard -0.758757541927\n",
      "revard -0.96578082866\n",
      "revard -1.57508613735\n",
      "revard -1.17804355335\n",
      "revard -0.808863178855\n",
      "revard -1.04402289295\n",
      "revard -1.62767952675\n",
      "revard -3.17988441782\n",
      "revard -2.14745331489\n",
      "Saved agent parameters to 'network_config_agent_0_layers_9_6_1.txt'\n",
      "train on map = 42\n",
      "revard -0.384\n",
      "revard -0.397500273209\n",
      "revard -0.395588585998\n",
      "revard -0.286258715445\n",
      "revard -0.0961704026558\n",
      "revard -0.064\n",
      "revard -0.192\n",
      "revard -1.248\n",
      "revard -1.984\n",
      "revard -1.58452359476\n",
      "revard -1.43544525054\n",
      "revard -1.02209707832\n",
      "revard -0.780162963892\n",
      "revard -1.15997408073\n",
      "revard -0.750986539381\n",
      "revard -0.391902556379\n",
      "revard -0.660994427176\n",
      "revard -0.384688290082\n",
      "revard -0.146653182893\n",
      "revard -0.14097105864\n",
      "Saved agent parameters to 'network_config_agent_0_layers_9_6_1.txt'\n",
      "train on map = 23\n",
      "revard -0.480631555587\n",
      "revard -0.240315777794\n",
      "revard -0.561851040401\n",
      "revard -1.34365440479\n",
      "revard -0.910371762639\n",
      "revard -1.75398464891\n",
      "revard -2.30105111813\n",
      "revard -2.70987754073\n",
      "revard -3.44958929775\n",
      "revard -1.89562354292\n",
      "revard -1.87719914742\n",
      "revard -2.5377349821\n",
      "revard -2.09021195426\n",
      "revard -1.34899754588\n",
      "revard -1.21603085803\n",
      "revard -1.75454179761\n",
      "revard -1.88628600495\n",
      "revard -1.58465367233\n",
      "revard -2.23647695168\n",
      "revard -1.664\n",
      "Saved agent parameters to 'network_config_agent_0_layers_9_6_1.txt'\n",
      "train on map = 15\n",
      "revard -0.2700302481\n",
      "revard -1.62385900116\n",
      "revard -3.2041461448\n",
      "revard -2.65200359111\n",
      "revard -1.87721921822\n",
      "revard -1.60553068219\n",
      "revard -0.790493690941\n",
      "revard -0.157480903563\n",
      "revard -0.096\n",
      "revard -0.297421761757\n",
      "revard -0.581888701048\n",
      "revard -0.748289487041\n",
      "revard -0.67356570647\n",
      "revard -0.656682846546\n",
      "revard -1.3090548587\n",
      "revard -2.59857730732\n",
      "revard -2.16834128742\n",
      "revard -0.564695029003\n",
      "revard -1.64965868474\n",
      "revard -2.70028176573\n",
      "Saved agent parameters to 'network_config_agent_0_layers_9_6_1.txt'\n",
      "train on map = 21\n",
      "revard -0.704\n",
      "revard -1.952\n",
      "revard -2.41671253518\n",
      "revard -1.33437984086\n",
      "revard -0.612594780261\n",
      "revard -0.186299458586\n",
      "revard -0.115310457015\n",
      "revard -0.023938473009\n",
      "revard 0.0\n",
      "revard -0.064\n",
      "revard -0.064\n",
      "revard 0.0\n",
      "revard -0.0948104465631\n",
      "revard -0.139927299497\n",
      "revard -0.665664444049\n",
      "revard -1.18259545694\n",
      "revard -1.37526898998\n",
      "revard -1.10177379279\n",
      "revard -1.14810635592\n",
      "revard -1.80974424809\n",
      "Saved agent parameters to 'network_config_agent_0_layers_9_6_1.txt'\n",
      "train on map = 42\n",
      "revard -1.59203537753\n",
      "revard -1.16054589863\n",
      "revard -0.871515917367\n",
      "revard -1.02900379204\n",
      "revard -1.08552311626\n",
      "revard -1.38002808198\n",
      "revard -1.43105692035\n",
      "revard -1.78615550324\n",
      "revard -1.77900979106\n",
      "revard -2.18896705874\n",
      "revard -2.51667076552\n",
      "revard -2.00239683255\n",
      "revard -2.23482071207\n",
      "revard -2.26393609653\n",
      "revard -2.26391686405\n",
      "revard -2.09808778219\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "phase((-1.0969788613784897+6.196558717535725j)) = 1.746011 was not found anywhere in the m",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-606283f7a8a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;31m# Учимся\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvisual\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m# чистим историю: не учимся повторно на старой карте, ускоряемся\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\stepic_neural_networks_public\\HW_3\\cars\\world.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, steps, visual)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0msteps\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvisual\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\stepic_neural_networks_public\\HW_3\\cars\\world.py\u001b[0m in \u001b[0;36mtransition\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     92\u001b[0m             \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoose_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvision\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m             next_agent_state, collision = self.physics.move(\n\u001b[1;32m---> 94\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magent_states\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m             )\n\u001b[0;32m     96\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcircles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mangle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magent_states\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_agent_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\stepic_neural_networks_public\\HW_3\\cars\\physics.py\u001b[0m in \u001b[0;36mmove\u001b[1;34m(self, car_state, action, *args, **kwargs)\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0macceleration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrotate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcar_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheading\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteering\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mpi\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macceleration\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mnew_position\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mposition\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mvelocity\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimedelta\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0macceleration\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimedelta\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0mcollision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_out_of_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_position\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcollision\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mCarState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposition\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m0.5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mvelocity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mcar_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheading\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollision\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\stepic_neural_networks_public\\HW_3\\cars\\physics.py\u001b[0m in \u001b[0;36mis_out_of_map\u001b[1;34m(self, position)\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;33m:\u001b[0m\u001b[1;32mreturn\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mnew_point\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mout\u001b[0m \u001b[0mof\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \"\"\"\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[0mcurrent_sector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefine_sector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0mcoefs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_line_coefs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcurrent_sector\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcurrent_sector\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\stepic_neural_networks_public\\HW_3\\cars\\utils.py\u001b[0m in \u001b[0;36mdefine_sector\u001b[1;34m(m, position)\u001b[0m\n\u001b[0;32m    141\u001b[0m             \u001b[1;31m# position does not lie between i-1-th and i-th points of m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"phase(%s) = %f was not found anywhere in the m\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposition\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposition\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: phase((-1.0969788613784897+6.196558717535725j)) = 1.746011 was not found anywhere in the m"
     ]
    }
   ],
   "source": [
    "for rap, steps in train_params:\n",
    "    agent.RANDOM_ACTION_P = rap\n",
    "\n",
    "    for map_seed in map_seeds:\n",
    "        print(\"train on map = {}\".format(map_seed))\n",
    "\n",
    "        # Меняем карту\n",
    "        w = create_map(seed=map_seed, agent=agent)\n",
    "\n",
    "        # Учимся\n",
    "        w.run(steps=steps, visual=False)\n",
    "\n",
    "        # чистим историю: не учимся повторно на старой карте, ускоряемся\n",
    "        agent.clear_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cmath import rect, phase, pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "m = generate_map(8, 5, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "position = -1.0969788613784897+6.196558717535725j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-9.424777960769378 -2.536968738261595 - -9.424777960769378 -2.536968738261595\n",
      "-2.536968738261595 -1.0022209839513132 - -2.536968738261595 -1.0022209839513132\n",
      "-1.0022209839513132 0.17944426583972284 - -1.0022209839513132 0.17944426583972284\n",
      "0.17944426583972284 1.145864733087902 - 0.17944426583972284 1.145864733087902\n",
      "1.145864733087902 1.3977272078977956 - 1.145864733087902 1.3977272078977956\n",
      "1.3977272078977956 1.6495507453753833 - 1.3977272078977956 1.6495507453753833\n",
      "1.6495507453753833 1.7433157100302203 - 1.6495507453753833 1.7433157100302203\n",
      "1.7433157100302203 -3.141592653589792 - -3.141592653589792 1.7433157100302203\n"
     ]
    }
   ],
   "source": [
    "cur_phase = phase(m[-1][0]) - 2 * pi\n",
    "for i in range(len(m)):\n",
    "    prev_phase = cur_phase\n",
    "    cur_phase = phase(m[i][0])\n",
    "    print(prev_phase, cur_phase,  \"-\", min(prev_phase, cur_phase), max(prev_phase, cur_phase))\n",
    "    if min(prev_phase, cur_phase) < phase(position) <= max(prev_phase, cur_phase):\n",
    "        # position does not lie between i-1-th and i-th points of m\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Смотрим вживую и продолжаем учиться"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "agent.RANDOM_ACTION_P = 0.00\n",
    "\n",
    "for map_seed in map_seeds:\n",
    "    print(\"train on map = {}\".format(map_seed))\n",
    "\n",
    "    # Меняем карту\n",
    "    w = create_map(seed=map_seed, agent=agent)\n",
    "\n",
    "    # Учимся\n",
    "    w.run(steps=None, visual=True)\n",
    "\n",
    "    # чистим историю: не учимся повторно на старой карте, ускоряемся\n",
    "    agent.clear_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оцениваем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"- time = {}, train_params = {}\".format(datetime.datetime.now(), train_params))\n",
    "\n",
    "for map_seed in map_seeds:\n",
    "    # Меняем карту\n",
    "    w = create_map(seed=map_seed, agent=agent)\n",
    "    \n",
    "    # оцениваем\n",
    "    revard = w.evaluate_agent(agent, steps=800, visual=False)\n",
    "    print(\"  - evaluate_agent on map = {}, reward = {}\".format(map_seed, revard))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train_params = [(0.2, 1000), (0.05, 1000)]\n",
    "  - evaluate_agent on map = 23, reward = -2.096\n",
    "  - evaluate_agent on map = 15, reward = -1.1392033828952342\n",
    "  - evaluate_agent on map = 21, reward = -0.008\n",
    "  - evaluate_agent on map = 42, reward = -0.016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Немного покатаемся для отладки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for map_seed in map_seeds:\n",
    "    # Меняем карту\n",
    "    w = create_map(seed=map_seed, agent=agent)\n",
    "    \n",
    "    # оцениваем\n",
    "    revard = w.evaluate_agent(agent, steps=200, visual=True)\n",
    "    print(\"evaluate_agent on map = {}, reward = {}\".format(map_seed, revard))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = w.agents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate([\n",
    "    np.array(agent.sensor_data_history)[:,:1],\n",
    "    np.array(agent.chosen_actions_history),\n",
    "    np.array(agent.reward_history).reshape(-1,1)\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.RANDOM_ACTION_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
